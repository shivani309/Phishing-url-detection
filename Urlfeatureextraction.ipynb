{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching https://www.southbankmosaics.com: argument of type 'NoneType' is not iterable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>URL</th>\n",
       "      <th>URLLength</th>\n",
       "      <th>Domain</th>\n",
       "      <th>DomainLength</th>\n",
       "      <th>IsDomainIP</th>\n",
       "      <th>TLD</th>\n",
       "      <th>URLSimilarityIndex</th>\n",
       "      <th>CharContinuationRate</th>\n",
       "      <th>TLDLegitimateProb</th>\n",
       "      <th>...</th>\n",
       "      <th>URLTitleMatchScore</th>\n",
       "      <th>HasFavicon</th>\n",
       "      <th>Robots</th>\n",
       "      <th>IsResponsive</th>\n",
       "      <th>NoOfURLRedirect</th>\n",
       "      <th>NoOfSelfRedirect</th>\n",
       "      <th>HasDescription</th>\n",
       "      <th>NoOfPopup</th>\n",
       "      <th>NoOfiFrame</th>\n",
       "      <th>HasExternalFormSubmit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.southbankmosaics.com</td>\n",
       "      <td>https://www.southbankmosaics.com</td>\n",
       "      <td>32</td>\n",
       "      <td>southbankmosaics</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   FILENAME                               URL  URLLength  \\\n",
       "0  www.southbankmosaics.com  https://www.southbankmosaics.com         32   \n",
       "\n",
       "             Domain  DomainLength  IsDomainIP  TLD  URLSimilarityIndex  \\\n",
       "0  southbankmosaics            24           0  com                   0   \n",
       "\n",
       "   CharContinuationRate  TLDLegitimateProb  ...  URLTitleMatchScore  \\\n",
       "0              0.129032                0.9  ...                   0   \n",
       "\n",
       "   HasFavicon  Robots  IsResponsive  NoOfURLRedirect  NoOfSelfRedirect  \\\n",
       "0           0       1             1                0                 0   \n",
       "\n",
       "   HasDescription  NoOfPopup  NoOfiFrame  HasExternalFormSubmit  \n",
       "0               0          0           0                      1  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# Use a custom cache directory\n",
    "extractor = tldextract.TLDExtract(cache_dir='/path/to/writable/cache_dir')\n",
    "extractor = tldextract.TLDExtract(cache_dir=False)\n",
    "\n",
    "def analyze_url(url):\n",
    "    features = {}\n",
    "    \n",
    "    # 1. FILENAME\n",
    "    features['FILENAME'] = url.split('//')[-1].split('/')[0]\n",
    "    \n",
    "    # 2. URL\n",
    "    features['URL'] = url\n",
    "    \n",
    "    # 3. URLLength\n",
    "    features['URLLength'] = len(url)\n",
    "    \n",
    "    # 4. Domain\n",
    "    extracted = tldextract.extract(url)\n",
    "    features['Domain'] = extracted.domain\n",
    "    \n",
    "    # 5. DomainLength\n",
    "    #features['DomainLength'] = len(features['Domain'])\n",
    "    protocol = urlparse(url).scheme  # Get the protocol (http or https)\n",
    "    full_domain = protocol + ('.' + extracted.subdomain if extracted.subdomain else '') + '.' + features['Domain']\n",
    "    features['DomainLength'] = sum(c.isalpha() for c in full_domain)\n",
    "\n",
    "    # 6. IsDomainIP\n",
    "    features['IsDomainIP'] = 1 if re.match(r'^\\d{1,3}(\\.\\d{1,3}){3}$', extracted.domain) else 0\n",
    "    \n",
    "    # 7. TLD\n",
    "    features['TLD'] = extracted.suffix\n",
    "    \n",
    "    # 8. URLSimilarityIndex (Placeholder for now)\n",
    "    features['URLSimilarityIndex'] = 0  # Implement actual logic for similarity score\n",
    "    \n",
    "    # 9. CharContinuationRate\n",
    "    features['CharContinuationRate'] = calculate_continuation_rate(url)\n",
    "    \n",
    "    # 10. TLDLegitimateProb (Placeholder for now)\n",
    "    features['TLDLegitimateProb'] = 0.9  # Example value, implement actual logic\n",
    "    \n",
    "    # 11. URLCharProb (Placeholder for now)\n",
    "    features['URLCharProb'] = 0.9  # Example value, implement actual logic\n",
    "    \n",
    "    # 12. TLDLength\n",
    "    features['TLDLength'] = len(features['TLD'])\n",
    "    \n",
    "    # 13. NoOfSubDomain\n",
    "    features['NoOfSubDomain'] = len(extracted.subdomain.split('.')) if extracted.subdomain else 0\n",
    "    \n",
    "    # 14. HasObfuscation and 15. NoOfObfuscatedChar\n",
    "    obfuscation_chars = re.findall(r'%|\\.|_|-|@|%20', url)\n",
    "    features['HasObfuscation'] = 1 if obfuscation_chars else 0\n",
    "    features['NoOfObfuscatedChar'] = len(''.join(obfuscation_chars))\n",
    "    \n",
    "    # 16. ObfuscationRatio\n",
    "    features['ObfuscationRatio'] = features['NoOfObfuscatedChar'] / features['URLLength'] if features['URLLength'] > 0 else 0\n",
    "    \n",
    "    # 17. NoOfLettersInURL\n",
    "    features['NoOfLettersInURL'] = sum(c.isalpha() for c in url)\n",
    "    \n",
    "    # 18. LetterRatioInURL\n",
    "    features['LetterRatioInURL'] = features['NoOfLettersInURL'] / features['URLLength'] if features['URLLength'] > 0 else 0\n",
    "    \n",
    "    # 19. NoOfDigitsInURL\n",
    "    features['NoOfDigitsInURL'] = sum(c.isdigit() for c in url)\n",
    "    \n",
    "    # 20. DigitRatioInURL\n",
    "    features['DigitRatioInURL'] = features['NoOfDigitsInURL'] / features['URLLength'] if features['URLLength'] > 0 else 0\n",
    "    \n",
    "    # 21. NoOfEqualsInURL\n",
    "    features['NoOfEqualsInURL'] = url.count('=')\n",
    "    \n",
    "    # 22. NoOfQMarkInURL\n",
    "    features['NoOfQMarkInURL'] = url.count('?')\n",
    "    \n",
    "    # 23. NoOfAmpersandInURL\n",
    "    features['NoOfAmpersandInURL'] = url.count('&')\n",
    "    \n",
    "    # 24. NoOfOtherSpecialCharsInURL\n",
    "    features['NoOfOtherSpecialCharsInURL'] = len(re.findall(r'[^a-zA-Z0-9:/?&=]', url))\n",
    "    \n",
    "    # 25. SpecialCharRatioInURL\n",
    "    features['SpecialCharRatioInURL'] = features['NoOfOtherSpecialCharsInURL'] / features['URLLength'] if features['URLLength'] > 0 else 0\n",
    "    \n",
    "    # 26. IsHTTPS\n",
    "    features['IsHTTPS'] = 1 if url.startswith('https://') else 0\n",
    "    \n",
    "    # 27. LineOfCode, 28. LargestLineLength, and other website features\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # 27. LineOfCode (Approximation)\n",
    "        features['LineOfCode'] = len(soup.prettify().splitlines())\n",
    "        \n",
    "        # 28. LargestLineLength\n",
    "        features['LargestLineLength'] = max(len(line) for line in soup.prettify().splitlines())\n",
    "        \n",
    "        # 29. HasTitle\n",
    "        title_tag = soup.find('title')\n",
    "        features['HasTitle'] = 1 if title_tag else 0\n",
    "        \n",
    "        # 30. Title\n",
    "        features['Title'] = title_tag.text if title_tag else ''\n",
    "        \n",
    "        # 31. DomainTitleMatchScore (Placeholder)\n",
    "        features['DomainTitleMatchScore'] = 0  # Implement actual logic\n",
    "        \n",
    "        # 32. URLTitleMatchScore (Placeholder)\n",
    "        features['URLTitleMatchScore'] = 0  # Implement actual logic\n",
    "        \n",
    "        # 33. HasFavicon\n",
    "        features['HasFavicon'] = 1 if soup.find('link', rel='icon') else 0\n",
    "        \n",
    "        # 34. Robots\n",
    "        features['Robots'] = 1 if requests.get(url + '/robots.txt').status_code == 200 else 0\n",
    "        \n",
    "        # 35. IsResponsive (Simple check)\n",
    "        features['IsResponsive'] = 1 if soup.find('meta', attrs={'name': 'viewport'}) else 0\n",
    "        \n",
    "        # 36. NoOfURLRedirect\n",
    "        features['NoOfURLRedirect'] = len(response.history)\n",
    "        \n",
    "        # 37. NoOfSelfRedirect (Not easy to implement without actual logging)\n",
    "        features['NoOfSelfRedirect'] = 0  # Implement actual logic\n",
    "        \n",
    "        # 38. HasDescription\n",
    "        features['HasDescription'] = 1 if soup.find('meta', attrs={'name': 'description'}) else 0\n",
    "        \n",
    "        # 39. NoOfPopup and 40. NoOfiFrame (Approximation)\n",
    "        features['NoOfPopup'] = 0  # Implement actual logic\n",
    "        features['NoOfiFrame'] = len(soup.find_all('iframe'))\n",
    "        \n",
    "        # 41. HasExternalFormSubmit\n",
    "        features['HasExternalFormSubmit'] = 1 if soup.find('form', action=lambda x: x and not x.startswith('/')) else 0\n",
    "        \n",
    "        # 42. HasSocialNet\n",
    "        features['HasSocialNet'] = 1 if soup.find('a', href=lambda x: 'facebook.com' in x or 'twitter.com' in x) else 0\n",
    "        \n",
    "        # 43. HasSubmitButton\n",
    "        features['HasSubmitButton'] = 1 if soup.find('input', type='submit') else 0\n",
    "        \n",
    "        # 44. HasHiddenFields\n",
    "        features['HasHiddenFields'] = 1 if soup.find('input', type='hidden') else 0\n",
    "        \n",
    "        # 45. HasPasswordField\n",
    "        features['HasPasswordField'] = 1 if soup.find('input', type='password') else 0\n",
    "        \n",
    "        # 46. Bank, 47. Pay, 48. Crypto (Placeholder)\n",
    "        features['Bank'] = 1 if 'bank' in url.lower() else 0\n",
    "        features['Pay'] = 1 if 'pay' in url.lower() else 0\n",
    "        features['Crypto'] = 1 if 'crypto' in url.lower() else 0\n",
    "        \n",
    "        # 49. HasCopyrightInfo\n",
    "        features['HasCopyrightInfo'] = 1 if soup.find(text=re.compile(r'copyright', re.I)) else 0\n",
    "        \n",
    "        # 50. NoOfImage\n",
    "        features['NoOfImage'] = len(soup.find_all('img'))\n",
    "        \n",
    "        # 51. NoOfCSS\n",
    "        features['NoOfCSS'] = len(soup.find_all('link', rel='stylesheet'))\n",
    "        \n",
    "        # 52. NoOfJS\n",
    "        features['NoOfJS'] = len(soup.find_all('script'))\n",
    "        \n",
    "        # 53. NoOfSelfRef (Approximation)\n",
    "        features['NoOfSelfRef'] = len(soup.find_all('a', href=lambda x: x and x.startswith(url)))\n",
    "        \n",
    "        # 54. NoOfEmptyRef\n",
    "        features['NoOfEmptyRef'] = len(soup.find_all('a', href=''))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "    \n",
    "    df = pd.DataFrame([features])  # Creating DataFrame from features dictionary\n",
    "    return df\n",
    "\n",
    "def calculate_continuation_rate(url):\n",
    "    \"\"\"\n",
    "    Calculate the rate of character continuation in the URL.\n",
    "    This is a simplified version and can be improved.\n",
    "    \"\"\"\n",
    "    continuation_count = sum(url[i] == url[i + 1] for i in range(len(url) - 1))\n",
    "    return continuation_count / (len(url) - 1) if len(url) > 1 else 0\n",
    "\n",
    "def clean_url(url):\n",
    "    # Remove any unwanted characters like tab\n",
    "    return url.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.southbankmosaics.com\t\"\n",
    "url = clean_url(url)\n",
    "features_df = analyze_url(url)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['www.southbankmosaics.com', 'https://www.southbankmosaics.com',\n",
       "        32, 'southbankmosaics', 24, 0, 'com', 0, 0.12903225806451613,\n",
       "        0.9, 0.9, 3, 1, 1, 2, 0.0625, 27, 0.84375, 0, 0.0, 0, 0, 0, 2,\n",
       "        0.0625, 1, 1282, 9467, 1,\n",
       "        'ข่าวสด ข่าววันนี้ ข่าวกีฬา ข่าวบันเทิง อัพเดทสดใหม่ทุกวัน – ข่าวสด ข่าวกีฬา ข่าวบันเทิง ข่าววันนี้ อัปเดตข่าวสารรวดเร็วทันใจ พร้อมรับชมสาระน่ารู้ต่างๆ ได้ฟรีตลอด 24ชั่วโมง',\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
